import streamlit as st
import openai
import chromadb

# Adicione este bloco no in√≠cio do seu chatbot.py
st.markdown("""
    <style>
        /* Esconde o header e o footer do Streamlit */
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
        header {visibility: hidden;}
    </style>
""", unsafe_allow_html=True)

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(page_title="Agente de Suporte", page_icon="ü§ñ")
st.title("ü§ñ Agente de Suporte GoEvo Compras")
st.caption("Fa√ßa uma pergunta.")

# --- Configura√ß√£o Segura das Chaves de API ---
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    CHROMA_API_KEY = st.secrets["CHROMA_API_KEY"]
    CHROMA_TENANT = st.secrets["CHROMA_TENANT"]
    CHROMA_DATABASE = st.secrets["CHROMA_DATABASE"]
except (FileNotFoundError, KeyError):
    st.error("ERRO: As chaves de API n√£o foram encontradas. Configure seu arquivo .streamlit/secrets.toml")
    st.stop()

# Cliente da OpenAI
client_openai = openai.OpenAI(api_key=OPENAI_API_KEY)

# --- Fun√ß√µes do Agente de IA ---

@st.cache_resource
def carregar_colecao_chroma():
    try:
        client = chromadb.CloudClient(
            api_key=CHROMA_API_KEY, tenant=CHROMA_TENANT, database=CHROMA_DATABASE
        )
        collection = client.get_collection("manual_do_sistema")
        st.success("Conectado √† base de conhecimento (ChromaDB)!")
        return collection
    except Exception as e:
        st.error(f"Erro ao conectar com o ChromaDB: {e}")
        return None

# --- NOVA FUN√á√ÉO DE CLASSIFICA√á√ÉO DE INTEN√á√ÉO ---
def identificar_intencao(pergunta):
    """
    Usa a IA para classificar a inten√ß√£o do usu√°rio.
    """
    try:
        prompt_classificador = f"""
        Voc√™ √© um classificador de inten√ß√£o de usu√°rio para um chatbot de suporte t√©cnico.
        Analise a frase do usu√°rio e classifique-a em uma das seguintes categorias:

        - SAUDACAO: Cumprimentos, agradecimentos, despedidas, gentilezas.
        - PERGUNTA_TECNICA: D√∫vidas sobre funcionalidades do sistema, como fazer algo no sistema.
        - ERRO: Relato de falha, erro t√©cnico, problema de funcionamento.
        - TREINAMENTO: Solicita√ß√£o de passo a passo, guia de uso, tutoriais.
        - FAQ: Perguntas comuns de neg√≥cio ou suporte que n√£o envolvem o sistema em si.

        Responda APENAS com uma destas palavras: SAUDACAO, PERGUNTA_TECNICA, ERRO, TREINAMENTO ou FAQ.

        Frase do usu√°rio: "{pergunta}"
        """

        resposta = client_openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt_classificador}],
            temperature=0,
            max_tokens=5
        )

        return resposta.choices[0].message.content.strip().upper()
            
    except Exception as e:
        print(f"Erro na classifica√ß√£o de inten√ß√£o: {e}")
        return "PERGUNTA_TECNICA"



def buscar_contexto(pergunta, colecao, n_results=3):
    if colecao is None: return ""
    embedding_pergunta = client_openai.embeddings.create(
        input=[pergunta], model="text-embedding-3-small"
    ).data[0].embedding
    resultados = colecao.query(query_embeddings=[embedding_pergunta], n_results=n_results)
    chunks_relevantes = [doc['texto_original'] for doc in resultados['metadatas'][0]]
    contexto = "\n\n---\n\n".join(chunks_relevantes)
    return contexto

def gerar_resposta_com_gpt(pergunta, contexto):
    prompt_sistema = """
    ## Persona:
    Voc√™ √© o GoEvo Assist, o especialista virtual e assistente de treinamento do sistema de compras GoEvo. Sua personalidade √© profissional, prestativa e did√°tica.

    ## Objetivo Principal:
    Seu objetivo √© guiar os usu√°rios de forma proativa para que eles consigam realizar o processo de compras com sucesso e autonomia, utilizando as melhores pr√°ticas do sistema.

    ## Regras de Comportamento e Tom de Voz:
    1.  **Seja Proativo:** Ap√≥s responder a pergunta principal do usu√°rio, se o contexto permitir, sugira o pr√≥ximo passo l√≥gico ou uma funcionalidade relacionada que possa ser √∫til.
        * Exemplo: Se o usu√°rio perguntar como criar um fornecedor, voc√™ pode responder e, ao final, sugerir: "Agora que o fornecedor foi criado, gostaria de saber como cadastrar um produto para ele?".
    2.  **Seja Claro e Estruturado:** Sempre que a resposta envolver um processo, formate-a em passos numerados (1., 2., 3.) ou em uma lista com marcadores (‚Ä¢) para facilitar a leitura e o acompanhamento.
    3.  **Seja Interativo:** Termine suas respostas com uma pergunta aberta para incentivar a continua√ß√£o da conversa e garantir que a d√∫vida do usu√°rio foi completamente resolvida. Use frases como "Isso te ajudou?", "Ficou claro?" ou "Posso te ajudar com mais algum detalhe sobre este processo?".

    ## Regras R√≠gidas de Uso do Contexto (Regras Anti--Alucina√ß√£o):
    1.  **REGRA MAIS IMPORTANTE:** Sua resposta deve ser baseada **√∫nica e exclusivamente** nas informa√ß√µes contidas no **CONTEXTO** fornecido abaixo. N√£o utilize nenhum conhecimento externo que voc√™ possua.
    2.  **SE A RESPOSTA N√ÉO ESTIVER NO CONTEXTO:** Se a pergunta do usu√°rio n√£o puder ser respondida com as informa√ß√µes do contexto, n√£o invente uma solu√ß√£o. Responda de forma clara e honesta: "N√£o encontrei informa√ß√µes espec√≠ficas sobre isso em nossa base de conhecimento. Voc√™ poderia tentar perguntar de uma forma diferente?"
    3.  **N√ÉO SE DESCULPE:** N√£o pe√ßa desculpas por usar apenas o contexto. Aja como um especialista consultando seu manual para fornecer a informa√ß√£o mais precisa.
    """
    
    resposta = client_openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": prompt_sistema},
            {"role": "user", "content": f"**CONTEXTO:**\n{contexto}\n\n**PERGUNTA:**\n{pergunta}"}
        ],
        temperature=0.7
    )
    return resposta.choices[0].message.content

# --- Interface do Chat ---
# REMOVEMOS A LISTA DE SAUDA√á√ïES DAQUI
RESPOSTA_SAUDACAO = "Ol√°! Eu sou L√©o, assistente virtual da GoEvo. Como posso te ajudar?"

colecao = carregar_colecao_chroma()
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if pergunta_usuario := st.chat_input("Qual a sua d√∫vida?"):
    st.session_state.messages.append({"role": "user", "content": pergunta_usuario})
    with st.chat_message("user"):
        st.markdown(pergunta_usuario)

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            
            # --- L√ìGICA DE ROTEAMENTO ATUALIZADA COM IA ---
            intencao_detectada = identificar_intencao(pergunta_usuario)
            
            # ROTA 1: A IA classificou como Sauda√ß√£o
            if intencao_detectada == "SAUDACAO":
                resposta_final = RESPOSTA_SAUDACAO
            
            # ROTA 2: A IA classificou como Pergunta T√©cnica
            else: # intencao_detectada == "PERGUNTA_TECNICA"
                if colecao is not None:
                    contexto_relevante = buscar_contexto(pergunta_usuario, colecao)
                    resposta_final = gerar_resposta_com_gpt(pergunta_usuario, contexto_relevante)
                else:
                    resposta_final = "Desculpe, estou com problemas para acessar a base de conhecimento."
            
            st.markdown(resposta_final)
    

    st.session_state.messages.append({"role": "assistant", "content": resposta_final})


