import streamlit as st
import openai
import chromadb

# --- Configura√ß√£o da P√°gina ---
st.set_page_config(page_title="GoEvo Assist", page_icon="ü§ñ")
st.title("ü§ñ Agente de Suporte GoEvo Compras")
st.caption("Fa√ßa uma pergunta.")

# --- Configura√ß√£o das Chaves de API ---
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    CHROMA_API_KEY = st.secrets["CHROMA_API_KEY"]
    CHROMA_TENANT = st.secrets["CHROMA_TENANT"]
    CHROMA_DATABASE = st.secrets["CHROMA_DATABASE"]
except (FileNotFoundError, KeyError):
    st.error("ERRO: As chaves de API n√£o foram encontradas. Configure seu arquivo .streamlit/secrets.toml")
    st.stop()

client_openai = openai.OpenAI(api_key=OPENAI_API_KEY)

# --- Fun√ß√µes do Agente de IA ---
@st.cache_resource
def carregar_colecoes_chroma():
    try:
        client = chromadb.CloudClient(
            api_key=CHROMA_API_KEY, tenant=CHROMA_TENANT, database=CHROMA_DATABASE
        )
        colecao_funcionalidades = client.get_collection("colecao_funcionalidades")
        colecao_parametros = client.get_collection("colecao_parametros")
        st.success("Conectado aos especialistas de Funcionalidades e Par√¢metros!")
        return colecao_funcionalidades, colecao_parametros
    except Exception as e:
        st.error(f"Erro ao conectar com a base de conhecimento: {e}")
        return None, None

def rotear_pergunta(pergunta):
    prompt_roteador = f"""
    Voc√™ √© um roteador de perguntas para um assistente de suporte de sistema.
    Classifique a pergunta do usu√°rio em uma de tr√™s categorias: SAUDACAO, FUNCIONALIDADE ou PARAMETRO.

    - SAUDACAO: Cumprimentos, conversas casuais (oi, ol√°, tudo bem?).
    - FUNCIONALIDADE: Perguntas sobre COMO FAZER algo no sistema (ex: "como eu crio uma cota√ß√£o?", "onde eu aprovo a SC?", "tem v√≠deo de como cadastrar produto?").
    - PARAMETRO: Perguntas sobre O QUE √â ou COMO CONFIGURAR um par√¢metro (ex: "o que faz o par√¢metro Libera√ß√£o de SC?", "quais os par√¢metros da omie?", "onde configuro o centro de custo?").

    Responda APENAS com a palavra SAUDACAO, FUNCIONALIDADE ou PARAMETRO.

    Pergunta do usu√°rio: "{pergunta}"
    """
    resposta = client_openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt_roteador}],
        temperature=0, max_tokens=10
    )
    intencao = resposta.choices[0].message.content.strip().upper()
    if "FUNCIONALIDADE" in intencao: return "FUNCIONALIDADE"
    if "PARAMETRO" in intencao: return "PARAMETRO"
    return "SAUDACAO"

# --- FUN√á√ÉO DE BUSCA ATUALIZADA ---
def buscar_contexto(pergunta, colecao, n_results=15): # <-- AJUSTE 1: Aumentado para 15
    """
    Busca os chunks, usa todos para o contexto de TEXTO,
    mas usa APENAS O MAIS RELEVANTE para o V√çDEO.
    """
    if colecao is None: return "", None
    
    embedding_pergunta = client_openai.embeddings.create(input=[pergunta], model="text-embedding-3-small").data[0].embedding
    
    resultados = colecao.query(
        query_embeddings=[embedding_pergunta],
        n_results=n_results
    )
    
    metadados_completos = resultados.get('metadatas', [[]])[0]
    
    contexto_texto = ""
    if metadados_completos:
        contexto_texto = "\n\n---\n\n".join([doc['texto_original'] for doc in metadados_completos])
    
    video_url = None
    if metadados_completos:
        primeiro_resultado_meta = metadados_completos[0]
        video_url = primeiro_resultado_meta.get('video_url')
            
    return contexto_texto, video_url

def gerar_resposta_com_gpt(pergunta, contexto, prompt_especialista):
    resposta = client_openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": prompt_especialista},
            {"role": "user", "content": f"**CONTEXTO:**\n{contexto}\n\n**PERGUNTA:**\n{pergunta}"}
        ],
        temperature=0.5
    )
    return resposta.choices[0].message.content

# --- Defini√ß√£o dos Prompts dos Especialistas ---
prompt_assistente_funcionalidades = """
## Persona:
Voc√™ √© o GoEvo Assist, o especialista virtual e assistente de treinamento do sistema de compras GoEvo. Sua personalidade √© profissional, prestativa e did√°tica.
## Objetivo Principal:
Seu objetivo √© guiar os usu√°rios de forma proativa para que eles consigam realizar o processo de compras com sucesso e autonomia, utilizando as melhores pr√°ticas do sistema.
## Regras de Comportamento e Tom de Voz:
1. Seja Proativo: Ap√≥s responder a pergunta principal, se o contexto permitir, sugira o pr√≥ximo passo l√≥gico ou uma funcionalidade relacionada.
2. Seja Claro e Estruturado: Sempre que a resposta envolver um processo, formate-a em passos numerados (1., 2., 3.).
3. Seja Interativo: Termine suas respostas com uma pergunta aberta como "Isso te ajudou?" ou "Posso te ajudar com mais algum detalhe?".
## Regras R√≠gidas de Uso do Contexto:
1. Sua resposta deve ser baseada √∫nica e exclusivamente nas informa√ß√µes contidas no CONTEXTO.
2. Se a resposta n√£o estiver no CONTEXTO, responda: "N√£o encontrei informa√ß√µes sobre isso em nossa base de conhecimento. Voc√™ poderia tentar perguntar de uma forma diferente?".
"""

# <-- AJUSTE 2: Prompt do Especialista em Par√¢metros Aprimorado
prompt_especialista_parametros = """
## Persona:
Voc√™ √© o GoEvo Assist, um especialista t√©cnico nos par√¢metros de configura√ß√£o do sistema de compras GoEvo. Sua personalidade √© precisa, completa e informativa.

## Objetivo Principal:
Seu objetivo √© listar e explicar de forma clara todos os par√¢metros relevantes encontrados no contexto que respondam √† pergunta do usu√°rio.

## Regras de Comportamento e Tom de Voz:
1.  **Seja Completo:** Se o contexto contiver m√∫ltiplos par√¢metros que se encaixam na pergunta do usu√°rio (ex: "par√¢metros do omie"), **liste TODOS eles**. N√£o resuma ou omita informa√ß√µes.
2.  **Formate com Clareza:** Para cada par√¢metro, estruture a resposta da seguinte forma, usando os dados do contexto:
    * **Par√¢metro:** (Use o "Titulo do Parametro")
    * **Finalidade:** (Use a "Sugest√£o de Descri√ß√£o")
    * **Quando √© Utilizado:** (Use o "Quando √© utilizado")
    * **Depend√™ncias:** (Use o "Necess√°rio ativa√ß√£o de outro parametro")
3.  **Use Negrito:** Destaque os t√≠tulos de cada se√ß√£o (como **Finalidade:**) para facilitar a leitura.

## Regras R√≠gidas de Uso do Contexto:
1.  **REGRA MAIS IMPORTANTE:** Sua resposta deve ser baseada **√∫nica e exclusivamente** nas informa√ß√µes contidas no **CONTEXTO**.
2.  **SE A RESPOSTA N√ÉO ESTIVER NO CONTEXTO:** Se o contexto n√£o contiver informa√ß√µes para responder √† pergunta, diga: "N√£o encontrei detalhes sobre este(s) par√¢metro(s) em nossa base de conhecimento. Poderia ser mais espec√≠fico?".
"""

# --- L√≥gica da Interface do Chat com Roteamento ---
RESPOSTA_SAUDACAO = "Ol√°! Eu sou o GoEvo Assist. Posso te ajudar com d√∫vidas sobre funcionalidades ou par√¢metros do sistema. O que voc√™ gostaria de saber?"
colecao_func, colecao_param = carregar_colecoes_chroma()

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant" and "video" in message and message["video"]:
            st.video(message["video"])

if pergunta_usuario := st.chat_input("Qual a sua d√∫vida?"):
    st.session_state.messages.append({"role": "user", "content": pergunta_usuario})
    with st.chat_message("user"):
        st.markdown(pergunta_usuario)

    with st.chat_message("assistant"):
        with st.spinner("Analisando sua pergunta..."):
            
            resposta_final = ""
            video_para_mostrar = None
            
            intencao = rotear_pergunta(pergunta_usuario)
            
            if intencao == "SAUDACAO":
                resposta_final = RESPOSTA_SAUDACAO
            
            else: # Se for FUNCIONALIDADE ou PARAMETRO
                colecao_para_buscar = None
                prompt_para_usar = None
                
                if intencao == "FUNCIONALIDADE":
                    st.spinner("Consultando o especialista em funcionalidades...")
                    colecao_para_buscar = colecao_func
                    prompt_para_usar = prompt_assistente_funcionalidades
                
                elif intencao == "PARAMETRO":
                    st.spinner("Consultando o especialista em par√¢metros...")
                    colecao_para_buscar = colecao_param
                    prompt_para_usar = prompt_especialista_parametros

                if colecao_para_buscar:
                    contexto, video_encontrado = buscar_contexto(pergunta_usuario, colecao_para_buscar)
                    resposta_final = gerar_resposta_com_gpt(pergunta_usuario, contexto, prompt_para_usar)
                    
                    if "N√£o encontrei" in resposta_final:
                        video_para_mostrar = None
                    else:
                        video_para_mostrar = video_encontrado
                else:
                    resposta_final = "Desculpe, a base de conhecimento necess√°ria n√£o est√° dispon√≠vel."
            
            st.markdown(resposta_final)
            if video_para_mostrar:
                st.video(video_para_mostrar)
    
    mensagem_assistente = {"role": "assistant", "content": resposta_final}
    if video_para_mostrar:
        mensagem_assistente["video"] = video_para_mostrar
    st.session_state.messages.append(mensagem_assistente)
